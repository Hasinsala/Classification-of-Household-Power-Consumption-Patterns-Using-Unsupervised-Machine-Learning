{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Lab03 - Data Mining Lab\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Lab 03 - Data Mining\n", "## 1. Connecting to Google Drive (Colab)"]}, {"cell_type": "code", "execution_count": 1, "metadata": {}, "outputs": [], "source": ["from google.colab import drive\n", "drive.mount('/content/drive')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 2. Loading the Dataset"]}, {"cell_type": "code", "execution_count": 2, "metadata": {}, "outputs": [], "source": ["import pandas as pd\n", "import numpy as np\n", "\n", "df = pd.read_csv('/content/drive/MyDrive/data/household_power_consumption.txt', sep=';', low_memory=False)\n", "df.replace('?', np.nan, inplace=True)\n", "df.dropna(inplace=True)\n", "df['Global_active_power'] = df['Global_active_power'].astype(float)\n", "df['DateTime'] = pd.to_datetime(df['Date'] + ' ' + df['Time'], format='%d/%m/%Y %H:%M:%S')\n", "df = df.drop(columns=['Date', 'Time'])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 3. Splitting the Dataset into Training, Validation, and Test Sets"]}, {"cell_type": "code", "execution_count": 3, "metadata": {}, "outputs": [], "source": ["from sklearn.model_selection import train_test_split\n", "\n", "train_df, temp_df = train_test_split(df, test_size=0.2, random_state=42)\n", "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n", "\n", "print(\"Training set:\", train_df.shape)\n", "print(\"Validation set:\", val_df.shape)\n", "print(\"Test set:\", test_df.shape)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 4. Data Preprocessing Function"]}, {"cell_type": "code", "execution_count": 4, "metadata": {}, "outputs": [], "source": ["from sklearn.preprocessing import StandardScaler\n", "\n", "def preprocess(df):\n", "    df = df.copy()\n", "    df['Hour'] = df['DateTime'].dt.hour\n", "    df['DayOfWeek'] = df['DateTime'].dt.dayofweek\n", "    df['Month'] = df['DateTime'].dt.month\n", "    df = df.drop(columns=['DateTime'])\n", "\n", "    scaler = StandardScaler()\n", "    df[df.columns] = scaler.fit_transform(df)\n", "    return df"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 5. Preprocess the Train, Validation, and Test Sets"]}, {"cell_type": "code", "execution_count": 5, "metadata": {}, "outputs": [], "source": ["train_processed = preprocess(train_df)\n", "val_processed = preprocess(val_df)\n", "test_processed = preprocess(test_df)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["*The datasets are now cleaned, scaled, and ready for clustering or supervised learning.*"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.8.5"}}, "nbformat": 4, "nbformat_minor": 4}